{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torchaudio\n",
    "!pip install -e .\n",
    "!pip install datasets\n",
    "!pip install huggingface_hub\n",
    "!pip install wandb\n",
    "!pip install cached_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data_perm/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /tmp/jieba.cache\n",
      "Loading model cost 0.687 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word segmentation module jieba initialized.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import sys\n",
    "sys.path.append('/data_perm/F5-TTS_custom/src/')\n",
    "\n",
    "from cached_path import cached_path\n",
    "from f5_tts.model import CFM, UNetT, DiT, Trainer\n",
    "from f5_tts.model.utils import get_tokenizer\n",
    "from f5_tts.model.dataset import load_dataset\n",
    "from importlib.resources import files\n",
    "import csv\n",
    "import json\n",
    "import zipfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import hf_hub_download\n",
    "\n",
    "local_dir = \"/data_perm/\"\n",
    "filename = \"all_mp3_data.zip\"\n",
    "\n",
    "hf_hub_download(repo_id=\"MonoraAI/test\", filename=filename, local_dir=local_dir, repo_type=\"dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "!unzip -qq  /data_perm/all_mp3_data.zip -d /data_perm/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /tmp/jieba.cache\n",
      "Loading model cost 0.668 seconds.\n",
      "Prefix dict has been built successfully.\n",
      "Word segmentation module jieba initialized.\n",
      "\n",
      "\n",
      "Saving to /data_perm/F5-TTS_custom/data/turkish_data_char ...\n",
      "Writing to raw.arrow ...: 100%|█████████| 21905/21905 [00:09<00:00, 2400.35it/s]\n",
      "\n",
      "For turkish_data_char, sample count: 21905\n",
      "For turkish_data_char, vocab size is: 113\n",
      "For turkish_data_char, total 94.01 hours\n"
     ]
    }
   ],
   "source": [
    "!python /data_perm/F5-TTS_custom/src/f5_tts/train/datasets/prepare_csv_wavs.py \\\n",
    "    /data_perm/all_mp3_data/ \\\n",
    "    /data_perm/F5-TTS_custom/data/turkish_data_char/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The above cell proces a .arrow type file. To view its content use the below cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data_perm/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['audio_path', 'text', 'duration'],\n",
      "    num_rows: 21905\n",
      "})\n",
      "{'audio_path': '/data_perm/all_mp3_data/wavs/CHP_sandıklara_sahip_çıkabilecek_mi_CHP_Ataşehir_Bld_Bşk_Adayı_Onursal_Adıgüzel__Fatih_Altaylı_0_1.mp3', 'text': ['S', 'o', 'h', 'b', 'e', 't', ' ', 'e', 't', 'm', 'e', ' ', 'v', 'e', ' ', 'y', 'a', 'p', 'm', 'a', 'y', 'ı', ' ', 'p', 'l', 'a', 'n', 'l', 'a', 'd', 'ı', ' ', 'k', 'l', 'a', 'r', 'ı', 'n', 'ı', ' ', 'ö', 'ğ', 'r', 'e', 'n', 'm', 'e', ' ', 'a', 'm', 'a', 'ç', 'l', 'ı', '.', ' ', 'A', 'm', 'a', ' ', 't', 'a', 'b', 'i', 'i', ' ', 'g', 'ö', 'r', 'e', 'v', ' ', 'b', 'a', 'ş', 'ı', ' ', 'n', 'd', 'a', 'k', 'i', ' ', 'b', 'e', 'l', 'e', 'd', 'i', 'y', 'e', ' ', 'b', 'a', 'ş', 'k', 'a', 'n', 'l', 'a', 'r', 'ı', ' ', 'y', 'l', 'a', ' ', 'a', 'd', 'a', 'y', 'l', 'a', 'r', ' ', 'a', 'r', 'a', 's', 'ı', ' ', 'n', 'd', 'a', ' ', 'd', 'a', ' ', 'e', 'l', 'b', 'e', 't', 't', 'e', ' ', 'b', 'i', 'r', ' ', 'a', 'y', 'r', 'ı', 'm', ' ', 'o', 'l', 'u', 'y', 'o', 'r', '.', ' ', 'G', 'ö', 'r', 'e', 'v', ' ', 'b', 'a', 'ş', 'ı', ' ', 'n', 'd', 'a', 'k', 'i', 'l', 'e', 'r', 'i', 'n', ' ', 'd', 'a', 'h', 'a', ' ', 'ç', 'o', 'k', ' ', 'y', 'a', 'p', 't', 'ı', ' ', 'k', 'l', 'a', 'r', 'ı', 'n', 'ı', ' ', 'a', 'd', 'a', 'y', 'l', 'a', 'r', 'a', ' ', 'i', 's', 'e', ' ', 'y', 'a', 'p', 'm', 'a', 'y', 'ı', ' ', 'p', 'l', 'a', 'n', 'l', 'a', 'd', 'ı', ' ', 'k', 'l', 'a', 'r', 'ı', 'n', 'ı', ' ', 's', 'o', 'r', 'm', 'a', 'y', 'ı', ' ', 't', 'e', 'r', 'c', 'i', 'h', ' ', 'e', 'd', 'i', 'y', 'o', 'r', 'u', 'z', '.'], 'duration': 14.24}\n"
     ]
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "# Path to the Arrow file\n",
    "arrow_file_path = \"/data_perm/F5-TTS_custom/data/turkish_data_char/raw.arrow\"\n",
    "\n",
    "# Load the dataset\n",
    "dataset = Dataset.from_file(arrow_file_path)\n",
    "\n",
    "# Print dataset info and a few samples\n",
    "print(dataset)\n",
    "print(dataset[1])  # View the first sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## setup wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a4058b2c4cf4220c074494541c001ce879794d05\n"
     ]
    }
   ],
   "source": [
    "wandb_project = \"F5_TTS_Turkish2\"\n",
    "wandb_run_name = \"F5_TTS_Turkish_Run\"\n",
    "wandb_resume_id = None\n",
    "import wandb\n",
    "os.environ[\"WANDB_API_KEY\"] = \"a4058b2c4cf4220c074494541c001ce879794d05\"\n",
    "print(wandb.api.api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------- Dataset Settings --------------------------- #\n",
    "target_sample_rate = 24000\n",
    "n_mel_channels = 100\n",
    "hop_length = 256\n",
    "win_length = 1024\n",
    "n_fft = 1024\n",
    "mel_spec_type = \"vocos\"  # 'vocos' or 'bigvgan'\n",
    "\n",
    "# -------------------------- Argument Variables ------------------------- #\n",
    "dataset_name = \"turkish_data\"\n",
    "learning_rate = 1e-5\n",
    "batch_size_per_gpu = 6400\n",
    "batch_size_type = \"frame\"\n",
    "max_samples = 64\n",
    "grad_accumulation_steps = 1\n",
    "max_grad_norm = 1.0\n",
    "epochs = 20\n",
    "num_warmup_updates = 300\n",
    "save_per_updates = 2000\n",
    "keep_last_n_checkpoints = 4\n",
    "last_per_updates = 2000\n",
    "finetune = True\n",
    "pretrain = None\n",
    "tokenizer = \"char\"\n",
    "tokenizer_path = None\n",
    "log_samples = False\n",
    "logger = \"wandb\"\n",
    "bnb_optimizer = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = \"/data_perm/F5-TTS_custom/ckpts/turkish/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import hf_hub_download\n",
    "\n",
    "local_dir = \"/data_perm/F5-TTS_custom/ckpts/turkish/\"\n",
    "filename = \"model_last.pt\"\n",
    "\n",
    "hf_hub_download(repo_id=\"MonoraAI/F5_TTS_turkish\", filename=filename, local_dir=local_dir, repo_type=\"model\")\n",
    "hf_hub_download(repo_id=\"MonoraAI/F5_TTS_turkish\", filename=\"vocab.txt\", local_dir=local_dir, repo_type=\"model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "vocab : 2554\n",
      "\n",
      "vocoder : vocos\n"
     ]
    }
   ],
   "source": [
    "# -------------------------- Training Settings -------------------------- #\n",
    "# Model parameters based on experiment name\n",
    "\n",
    "model_cls = DiT\n",
    "model_cfg = dict(dim=1024, depth=22, heads=16, ff_mult=2, text_dim=512, conv_layers=4)\n",
    "\n",
    "vocab_char_map, vocab_size = get_tokenizer(\"/data_perm/F5-TTS_custom/ckpts/turkish/vocab.txt\", \"custom\")\n",
    "\n",
    "print(\"\\nvocab :\", vocab_size)\n",
    "print(\"\\nvocoder :\", mel_spec_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmonoraai\u001b[0m (\u001b[33mmonoraai-monora\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data_perm/F5-TTS_custom/wandb/run-20250131_004107-ebfp76cr</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/monoraai-monora/F5_TTS_Turkish2/runs/ebfp76cr' target=\"_blank\">F5_TTS_Turkish_Run</a></strong> to <a href='https://wandb.ai/monoraai-monora/F5_TTS_Turkish2' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/monoraai-monora/F5_TTS_Turkish2' target=\"_blank\">https://wandb.ai/monoraai-monora/F5_TTS_Turkish2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/monoraai-monora/F5_TTS_Turkish2/runs/ebfp76cr' target=\"_blank\">https://wandb.ai/monoraai-monora/F5_TTS_Turkish2/runs/ebfp76cr</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using logger: wandb\n",
      "Loading dataset ...\n"
     ]
    }
   ],
   "source": [
    "mel_spec_kwargs = dict(\n",
    "    n_fft=n_fft,\n",
    "    hop_length=hop_length,\n",
    "    win_length=win_length,\n",
    "    n_mel_channels=n_mel_channels,\n",
    "    target_sample_rate=target_sample_rate,\n",
    "    mel_spec_type=mel_spec_type,\n",
    ")\n",
    "\n",
    "model = CFM(\n",
    "    transformer=model_cls(**model_cfg, text_num_embeds=vocab_size, mel_dim=n_mel_channels),\n",
    "    mel_spec_kwargs=mel_spec_kwargs,\n",
    "    vocab_char_map=vocab_char_map,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model,\n",
    "    epochs,\n",
    "    learning_rate,\n",
    "    num_warmup_updates=num_warmup_updates,\n",
    "    save_per_updates=save_per_updates,\n",
    "    keep_last_n_checkpoints=keep_last_n_checkpoints,\n",
    "    checkpoint_path=checkpoint_path,\n",
    "    batch_size=batch_size_per_gpu,\n",
    "    batch_size_type=batch_size_type,\n",
    "    max_samples=max_samples,\n",
    "    grad_accumulation_steps=grad_accumulation_steps,\n",
    "    max_grad_norm=max_grad_norm,\n",
    "    logger=\"wandb\",\n",
    "    wandb_project= wandb_project,\n",
    "    wandb_run_name= wandb_run_name,\n",
    "    wandb_resume_id=wandb_resume_id,\n",
    "    log_samples=log_samples,\n",
    "    last_per_updates=last_per_updates,\n",
    "    bnb_optimizer=bnb_optimizer,\n",
    ")\n",
    "\n",
    "train_dataset = load_dataset(dataset_name, tokenizer, dataset_type=\"CustomDataset\", mel_spec_kwargs=mel_spec_kwargs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sorting with sampler... if slow, check whether dataset is provided with duration: 100%|██████████| 21905/21905 [00:00<00:00, 1591840.00it/s]\n",
      "Creating dynamic batches with 6400 audio frames per gpu: 100%|██████████| 21905/21905 [00:00<00:00, 1919125.81it/s]\n",
      "/data_perm/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved last checkpoint at update 4000\n",
      "Saved last checkpoint at update 6000\n",
      "Saved last checkpoint at update 8000\n",
      "Removed old checkpoint: model_2000.pt\n",
      "Saved last checkpoint at update 10000\n",
      "Removed old checkpoint: model_4000.pt\n",
      "Saved last checkpoint at update 12000\n",
      "Removed old checkpoint: model_6000.pt\n",
      "Saved last checkpoint at update 14000\n",
      "Removed old checkpoint: model_8000.pt\n",
      "Saved last checkpoint at update 16000\n",
      "Removed old checkpoint: model_10000.pt\n",
      "Saved last checkpoint at update 18000\n",
      "Removed old checkpoint: model_12000.pt\n",
      "Saved last checkpoint at update 20000\n",
      "Removed old checkpoint: model_14000.pt\n",
      "Saved last checkpoint at update 22000\n",
      "Removed old checkpoint: model_16000.pt\n",
      "Saved last checkpoint at update 24000\n",
      "Removed old checkpoint: model_18000.pt\n",
      "Saved last checkpoint at update 26000\n",
      "Removed old checkpoint: model_20000.pt\n",
      "Saved last checkpoint at update 28000\n",
      "Removed old checkpoint: model_22000.pt\n",
      "Saved last checkpoint at update 30000\n",
      "Removed old checkpoint: model_24000.pt\n",
      "Saved last checkpoint at update 32000\n",
      "Removed old checkpoint: model_26000.pt\n",
      "Saved last checkpoint at update 34000\n",
      "Removed old checkpoint: model_28000.pt\n",
      "Saved last checkpoint at update 36000\n",
      "Removed old checkpoint: model_30000.pt\n",
      "Saved last checkpoint at update 38000\n",
      "Removed old checkpoint: model_32000.pt\n",
      "Saved last checkpoint at update 40000\n",
      "Removed old checkpoint: model_34000.pt\n",
      "Saved last checkpoint at update 42000\n",
      "Removed old checkpoint: model_36000.pt\n",
      "Saved last checkpoint at update 44000\n",
      "Removed old checkpoint: model_38000.pt\n",
      "Saved last checkpoint at update 46000\n",
      "Removed old checkpoint: model_40000.pt\n",
      "Saved last checkpoint at update 48000\n",
      "Removed old checkpoint: model_42000.pt\n",
      "Saved last checkpoint at update 50000\n",
      "Removed old checkpoint: model_44000.pt\n",
      "Saved last checkpoint at update 52000\n",
      "Removed old checkpoint: model_46000.pt\n",
      "Saved last checkpoint at update 54000\n",
      "Removed old checkpoint: model_48000.pt\n",
      "Saved last checkpoint at update 56000\n",
      "Removed old checkpoint: model_50000.pt\n",
      "Saved last checkpoint at update 58000\n",
      "Removed old checkpoint: model_52000.pt\n",
      "Saved last checkpoint at update 60000\n",
      "Removed old checkpoint: model_54000.pt\n",
      "Saved last checkpoint at update 62000\n",
      "Removed old checkpoint: model_56000.pt\n",
      "Saved last checkpoint at update 64000\n",
      "Removed old checkpoint: model_58000.pt\n",
      "Saved last checkpoint at update 66000\n",
      "Removed old checkpoint: model_60000.pt\n",
      "Saved last checkpoint at update 68000\n",
      "Removed old checkpoint: model_62000.pt\n",
      "Saved last checkpoint at update 70000\n",
      "Removed old checkpoint: model_64000.pt\n",
      "Saved last checkpoint at update 72000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/data_perm/F5-TTS_custom/src/f5_tts/model/trainer.py:353\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, train_dataset, num_workers, resumable_with_seed)\u001b[0m\n\u001b[1;32m    348\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mlog({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mduration loss\u001b[39m\u001b[38;5;124m\"\u001b[39m: dur_loss\u001b[38;5;241m.\u001b[39mitem()}, step\u001b[38;5;241m=\u001b[39mglobal_update)\n\u001b[1;32m    350\u001b[0m loss, cond, pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel(\n\u001b[1;32m    351\u001b[0m     mel_spec, text\u001b[38;5;241m=\u001b[39mtext_inputs, lens\u001b[38;5;241m=\u001b[39mmel_lengths, noise_scheduler\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnoise_scheduler\n\u001b[1;32m    352\u001b[0m )\n\u001b[0;32m--> 353\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maccelerator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    355\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_grad_norm \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39msync_gradients:\n\u001b[1;32m    356\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mclip_grad_norm_(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mparameters(), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_grad_norm)\n",
      "File \u001b[0;32m/data_perm/.venv/lib/python3.10/site-packages/accelerate/accelerator.py:2246\u001b[0m, in \u001b[0;36mAccelerator.backward\u001b[0;34m(self, loss, **kwargs)\u001b[0m\n\u001b[1;32m   2244\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlomo_backward(loss, learning_rate)\n\u001b[1;32m   2245\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2246\u001b[0m     \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/data_perm/.venv/lib/python3.10/site-packages/torch/_tensor.py:581\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    571\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    572\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    573\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    574\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    579\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    580\u001b[0m     )\n\u001b[0;32m--> 581\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    582\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    583\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/data_perm/.venv/lib/python3.10/site-packages/torch/autograd/__init__.py:347\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    342\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    344\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    345\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 347\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    348\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    349\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    350\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    351\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    352\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    353\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    355\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/data_perm/.venv/lib/python3.10/site-packages/torch/autograd/graph.py:825\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    823\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    824\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 825\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    826\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    827\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    828\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    829\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainer.train(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "model_last.pt: 100%|██████████| 5.39G/5.39G [01:52<00:00, 48.1MB/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/MonoraAI/F5_TTS_turkish/commit/855139d7e92b054b33cc27f861d0976618ee286f', commit_message='Upload /model_last.pt with huggingface_hub', commit_description='', oid='855139d7e92b054b33cc27f861d0976618ee286f', pr_url=None, repo_url=RepoUrl('https://huggingface.co/MonoraAI/F5_TTS_turkish', endpoint='https://huggingface.co', repo_type='model', repo_id='MonoraAI/F5_TTS_turkish'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from huggingface_hub import HfApi\n",
    "api = HfApi()\n",
    "\n",
    "# Upload all the content from the local folder to your remote Space.\n",
    "# By default, files are uploaded at the root of the repo\n",
    "api.upload_file(\n",
    "    path_or_fileobj=\"/data_perm/F5-TTS_custom/ckpts/turkish/model_last.pt\",\n",
    "    path_in_repo = \"/model_last.pt\",\n",
    "    repo_id=\"MonoraAI/F5_TTS_turkish\",\n",
    "    repo_type=\"model\",\n",
    ")\n",
    "\n",
    "api.upload_file(\n",
    "    path_or_fileobj=\"/data_perm/F5-TTS_custom/ckpts/turkish/vocab.txt\",\n",
    "    path_in_repo = \"/vocab.txt\",\n",
    "    repo_id=\"MonoraAI/F5_TTS_turkish\",\n",
    "    repo_type=\"model\",\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
